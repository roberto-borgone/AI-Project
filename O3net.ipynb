{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLProject.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9QcGnGPdX2C",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Install requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9O3aM3Tb28q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install 'torch==1.3.1'\n",
        "!pip3 install 'torchvision==0.4.2'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo942LMOdlh4",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DokFOdD1dJEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import copy \n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "from torch.autograd import Function\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import alexnet\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import random\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIDLJuIXK_vh",
        "colab_type": "text"
      },
      "source": [
        "**Set Arguments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5PkYfqfK_SA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = 'cuda' # 'cuda' or 'cpu'\n",
        "\n",
        "NUM_CLASSES = 101 # 101 + 1: There is am extra Background class that should be removed \n",
        "\n",
        "BATCH_SIZE = 256     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "LR = 1e-3            # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = 30      # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 10       # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = 10\n",
        "\n",
        "IMG_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp')\n",
        "\n",
        "NUM_CLASSES = 4      # Network output\n",
        "\n",
        "RANDOM_SEARCH = True # serve per caricare i pesi nella rete senza fare di nuovo il training con i nuovi parametri\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gwii0TBHvzh",
        "colab_type": "text"
      },
      "source": [
        "**Define Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUDdw4j2H0Mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ImageNet values\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "\n",
        "# Define transforms for the train phase\n",
        "train_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize( mean, std )                                    \n",
        "])\n",
        "\n",
        "# Define transforms for the evaluation phase\n",
        "eval_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize( mean, std )                                    \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qYIHPzYLY7i",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfVq_uDHLbsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone github repository with data\n",
        "if not os.path.isdir('./Homework3-PACS'):\n",
        "  !git clone https://github.com/MachineLearning2020/Homework3-PACS.git\n",
        "\n",
        "DATA_DIR = 'Homework3-PACS/PACS/'\n",
        "\n",
        "# Prepare Pytorch train/test Datasets\n",
        "photo_dataset = torchvision.datasets.ImageFolder(DATA_DIR+\"photo\", transform=train_transform)\n",
        "art_dataset = torchvision.datasets.ImageFolder(DATA_DIR+\"art_painting\", transform=eval_transform)\n",
        "cartoon_dataset = torchvision.datasets.ImageFolder(DATA_DIR+\"cartoon\", transform=eval_transform)\n",
        "sketch_dataset = torchvision.datasets.ImageFolder(DATA_DIR+\"sketch\", transform=eval_transform)\n",
        "\n",
        "# Check dataset sizes\n",
        "print('Photo Dataset: {}'.format(len(photo_dataset)))\n",
        "print('Art Dataset: {}'.format(len(art_dataset)))\n",
        "print('Cartoon Dataset: {}'.format(len(art_dataset)))\n",
        "print('Sketch Dataset: {}'.format(len(sketch_dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYEDQ7Z21ldN",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Dataloaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VriRw8SI1nle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "\n",
        "photo_dataloader = DataLoader(photo_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "art_dataloader = DataLoader(art_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4,drop_last=True)\n",
        "\n",
        "cartoon_dataloader = DataLoader(cartoon_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4,drop_last=True)\n",
        "\n",
        "sketch_dataloader = DataLoader(sketch_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4,drop_last=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHcBjRUnN3bA",
        "colab_type": "text"
      },
      "source": [
        "Network multi branch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fJHY9VRkIQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConcatLayer(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, fc6_1 ,fc6_2, fc6_3 ,fc6_4):\n",
        "        concatenation = torch.stack([fc6_1, fc6_2,fc6_3,fc6_4], dim=0) # esempio (3,4) (3,4)  ---> ( 2, 3, 4 )  oppure ( 4096 )( 4096 ) --> (2,4096)\n",
        "        #return concatenation.view_as(concatenation)\n",
        "        return concatenation\n",
        "        \n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return grad_output\n",
        "\n",
        "\n",
        "class OOONet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(OOONet, self).__init__()\n",
        "        \n",
        "        self.branch1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),                   #FC 6 \n",
        "            nn.ReLU(inplace=True),\n",
        "           \n",
        "        )\n",
        "        self.branch2 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),                   #FC 6 \n",
        "            nn.ReLU(inplace=True),\n",
        "           \n",
        "        )\n",
        "        self.branch3 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),                   #FC 6 \n",
        "            nn.ReLU(inplace=True),\n",
        "           \n",
        "        )\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),  #CONV 5 \n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),                   #FC 6 \n",
        "            nn.ReLU(inplace=True),\n",
        "           \n",
        "        )        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "     \n",
        "        #Livelli di fusione!!!!!!!\n",
        "        self.concatLayer = ConcatLayer()\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            \"\"\"\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),                   #FC 6 \n",
        "            nn.ReLU(inplace=True),\n",
        "            \"\"\"\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, NUM_CLASSES ),\n",
        "        )\n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "        #bisogna definire X perch√® dovrebbe essere un vettore di 4 immagini.\n",
        "        x0 = self.features(x[0])\n",
        "        x0 = self.avgpool(x0)\n",
        "        output_branch1 = torch.flatten(x0, 1)\n",
        "\n",
        "        x1 = self.features(x[1])\n",
        "        x1 = self.avgpool(x1)\n",
        "        output_branch2 = torch.flatten(x1, 1)\n",
        "\n",
        "        x2 = self.features(x[2])\n",
        "        x2 = self.avgpool(x2)\n",
        "        output_branch3 = torch.flatten(x2, 1)\n",
        "\n",
        "        x3 = self.features(x[3])\n",
        "        x3 = self.avgpool(x3)\n",
        "        output_branch4 = torch.flatten(x3, 1)\n",
        "\n",
        "        x = self.concatLayer.apply(output_branch1,output_branch2,output_branch3,output_branch4) \n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def buildO3Net ():\n",
        "\n",
        "    model = alexnet(pretrained=True)\n",
        "\n",
        "    net =  OOONet()\n",
        "    #0,3,6,8,10,14\n",
        "\n",
        "    #DEEP COPY FEATURES OF BRANCH 1\n",
        "\n",
        "    net.branch1[0].weight.data = copy.deepcopy(model.features[0].weight.data)\n",
        "    net.branch1[0].bias.data = copy.deepcopy(model.features[0].bias.data)   \n",
        "    net.branch1[3].weight.data = copy.deepcopy(model.features[3].weight.data)\n",
        "    net.branch1[3].bias.data = copy.deepcopy(model.features[3].bias.data)\n",
        "    net.branch1[6].weight.data = copy.deepcopy(model.features[6].weight.data)\n",
        "    net.branch1[6].bias.data = copy.deepcopy(model.features[6].bias.data)\n",
        "    net.branch1[8].weight.data = copy.deepcopy(model.features[8].weight.data)\n",
        "    net.branch1[8].bias.data = copy.deepcopy(model.features[8].bias.data)\n",
        "    net.branch1[10].weight.data = copy.deepcopy(model.features[10].weight.data)\n",
        "    net.branch1[10].bias.data = copy.deepcopy(model.features[10].bias.data)\n",
        "    net.branch1[14].weight.data = copy.deepcopy(model.classifier[1].weight.data)\n",
        "    net.branch1[14].bias.data = copy.deepcopy(model.classifier[1].bias.data)\n",
        "\n",
        "\n",
        "    #DEEP COPY FEATURES OF BRANCH 2\n",
        "\n",
        "    net.branch2[0].weight.data = copy.deepcopy(model.features[0].weight.data)\n",
        "    net.branch2[0].bias.data = copy.deepcopy(model.features[0].bias.data)   \n",
        "    net.branch2[3].weight.data = copy.deepcopy(model.features[3].weight.data)\n",
        "    net.branch2[3].bias.data = copy.deepcopy(model.features[3].bias.data)\n",
        "    net.branch2[6].weight.data = copy.deepcopy(model.features[6].weight.data)\n",
        "    net.branch2[6].bias.data = copy.deepcopy(model.features[6].bias.data)\n",
        "    net.branch2[8].weight.data = copy.deepcopy(model.features[8].weight.data)\n",
        "    net.branch2[8].bias.data = copy.deepcopy(model.features[8].bias.data)\n",
        "    net.branch2[10].weight.data = copy.deepcopy(model.features[10].weight.data)\n",
        "    net.branch2[10].bias.data = copy.deepcopy(model.features[10].bias.data)\n",
        "    net.branch2[14].weight.data = copy.deepcopy(model.classifier[1].weight.data)\n",
        "    net.branch2[14].bias.data = copy.deepcopy(model.classifier[1].bias.data)\n",
        "\n",
        "    #DEEP COPY FEATURES OF BRANCH 3\n",
        "\n",
        "    net.branch3[0].weight.data = copy.deepcopy(model.features[0].weight.data)\n",
        "    net.branch3[0].bias.data = copy.deepcopy(model.features[0].bias.data)   \n",
        "    net.branch3[3].weight.data = copy.deepcopy(model.features[3].weight.data)\n",
        "    net.branch3[3].bias.data = copy.deepcopy(model.features[3].bias.data)\n",
        "    net.branch3[6].weight.data = copy.deepcopy(model.features[6].weight.data)\n",
        "    net.branch3[6].bias.data = copy.deepcopy(model.features[6].bias.data)\n",
        "    net.branch3[8].weight.data = copy.deepcopy(model.features[8].weight.data)\n",
        "    net.branch3[8].bias.data = copy.deepcopy(model.features[8].bias.data)\n",
        "    net.branch3[10].weight.data = copy.deepcopy(model.features[10].weight.data)\n",
        "    net.branch3[10].bias.data = copy.deepcopy(model.features[10].bias.data)\n",
        "    net.branch3[14].weight.data = copy.deepcopy(model.classifier[1].weight.data)\n",
        "    net.branch3[14].bias.data = copy.deepcopy(model.classifier[1].bias.data)\n",
        "\n",
        "    #DEEP COPY FEATURES OF BRANCH 4\n",
        "\n",
        "    net.branch4[0].weight.data = copy.deepcopy(model.features[0].weight.data)\n",
        "    net.branch4[0].bias.data = copy.deepcopy(model.features[0].bias.data)   \n",
        "    net.branch4[3].weight.data = copy.deepcopy(model.features[3].weight.data)\n",
        "    net.branch4[3].bias.data = copy.deepcopy(model.features[3].bias.data)\n",
        "    net.branch4[6].weight.data = copy.deepcopy(model.features[6].weight.data)\n",
        "    net.branch4[6].bias.data = copy.deepcopy(model.features[6].bias.data)\n",
        "    net.branch4[8].weight.data = copy.deepcopy(model.features[8].weight.data)\n",
        "    net.branch4[8].bias.data = copy.deepcopy(model.features[8].bias.data)\n",
        "    net.branch4[10].weight.data = copy.deepcopy(model.features[10].weight.data)\n",
        "    net.branch4[10].bias.data = copy.deepcopy(model.features[10].bias.data)\n",
        "    net.branch4[14].weight.data = copy.deepcopy(model.classifier[1].weight.data)\n",
        "    net.branch4[14].bias.data = copy.deepcopy(model.classifier[1].bias.data)\n",
        "\n",
        "    #DEEP COPY OF LAST TWO FC LAYERS\n",
        "\n",
        "    net.classifier[4].weight.data = copy.deepcopy(model.classifier[4].weight.data)\n",
        "    net.classifier[4].bias.data = copy.deepcopy(model.classifier[4].bias.data)\n",
        "    net.classifier[6].weight.data = copy.deepcopy(model.classifier[6].weight.data)\n",
        "    net.classifier[6].bias.data = copy.deepcopy(model.classifier[6].bias.data)\n",
        "\n",
        "    return net\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tLYn6jdMZ3A",
        "colab_type": "text"
      },
      "source": [
        "**Plot Graph Function** <br>\n",
        "It s a function used for plotting the graph of all the set of hyperparameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8seNQwB1Madf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_graph(epoches ,val_data , train_data, lr,alpha,wd,dp ,xlabel ,ylabel):\n",
        "  \n",
        "  epoches = range(epoches)\n",
        "  plt.plot(epoches,val_data,label=\"val\")\n",
        "  plt.plot(epoches,train_data,label=\"train\")\n",
        "  plt.title('Hyperparameters - LR={} ALPHA={} WD={} DP={}'.format(lr,alpha,wd,dp))\n",
        "  plt.xlabel(xlabel)\n",
        "  plt.ylabel(ylabel)\n",
        "  plt.legend()\n",
        "  plt.show()    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIG4zcothAhZ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Shows data examples**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FWpK-S8hEhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_img=10\n",
        "\n",
        "def imshow(inp,ax, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    ax.imshow(inp)\n",
        "\n",
        "def visualize(net, dataloader, num):\n",
        "  net.to(DEVICE)\n",
        "  net.train(False)\n",
        "  fig = plt.figure(figsize=(15,7))\n",
        "  images_so_far = 0\n",
        "\n",
        "  for images,labels in dataloader:\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    outputs = net(images)\n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "    for j in range(images.size()[0]):\n",
        "     \n",
        "      images_so_far += 1\n",
        "      ax = plt.subplot(2, num/2, images_so_far)\n",
        "      ax.axis('off')\n",
        "      ax.set_title('predicted: {}\\nreal: {}'.format(art_dataset.classes[preds[j]],art_dataset.classes[labels[j]]))\n",
        "      imshow(images.cpu().data[j],ax)\n",
        "      if images_so_far == num:\n",
        "        return\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "visualize(net, art_dataloader, num_img)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}